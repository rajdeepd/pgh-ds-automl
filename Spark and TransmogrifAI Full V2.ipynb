{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We will be using TransmogrifAI to help build a model so we may make a submission to the [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) Kaggle competition.  This is an excellent challenge if you are new to data science, and its aim (in my opinion) is to introduce\n",
    "* feature engineering\n",
    "* binary classification\n",
    "\n",
    "We will also use it to get a quick intro to Scala, Spark and TransmogrifAI.\n",
    "\n",
    "#### Competition Description\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/pic1.PNG\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Want to see my Transmogrif-AI-er? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransmogrifAI will be helpful in a few regards. \n",
    "\n",
    "* It will help automate __feature engineering__.  \n",
    "* Machine learning model selection\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is usually a complex and time intensive process used to develop features for a machine learning model.  Crafted the right features for an ML model usually depends on subject matter expertise, experience and trial and error, But keep in mind, there are components to feature engineering that are ripe for automation.  Consider categorical variables - you need to come up with a numeric representation of categorical variables.  You could automate a workflow by always choosing to one hot encode categorical data.  There are other thing that you could automate by using rules of thumbs or more complex methods of vectorization (e.g., entity embedding), but be advised, you will not find that automated feature engineering to be as good as a knowledgable SME.  \n",
    "\n",
    "### Automated Feature Engineering\n",
    "\n",
    "You can't always rely on automated methods over domain experience.  Consider the following example.  A feature is your dataset has missing values.  Without knowing the context for the problem or what the feature represent, a person may decide that mean value replacement should be used to impute the data.  But suppose that the feature has represents a customers credit utilization rate.  While we may not know what a credit utilization rate is, our good buddy Keith does.  Keith tells us that __credit utilization rate__ _is the amount of revolving credit you're currently using divided by the total amount of revolving credit you have available_.  Good to know!  But why wouldn't it be missng?  Keith informs us that while some customers may have credit (ala a car loan), they may not have access to revolving credit.    \n",
    "\n",
    "Hmm, so a missing value for credit utilization rate may mean this person can't get revolving credit, is wealthy and doesn need it, or something else.  So be aware - automated feature engineering isn't an end all, but there are some work arounds (imputation and null value tracking).\n",
    "\n",
    "## Machine Learning Model Selection\n",
    "\n",
    "TransmogrifAI will try a number of preselected models with sets of predetermined hyperparameters.  The best is chosen via crossvalidation and made available for scoring.  Additionally we can gather some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Scala Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "version 2.11.12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scala.util.Properties.versionString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get TransmogrifAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5775496-c0ed-4e44-b52b-609c26158f37",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add mvn com.salesforce.transmogrifai transmogrifai-core_2.11 0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9034cc-9a3b-4776-a8e0-d3accc6539c1",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add mvn org.apache.spark spark-mllib_2.11 2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://bailiwick.io/2017/08/21/using-xgboost-with-the-titanic-dataset-from-kaggle/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.SparkConf\r\n",
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.SparkContext\r\n",
       "import org.apache.spark.sql.functions.udf\r\n",
       "import com.salesforce.op._\r\n",
       "import com.salesforce.op.features._\r\n",
       "import com.salesforce.op.features.types._\r\n",
       "import com.salesforce.op.stages.impl.classification._\r\n",
       "import com.salesforce.op.evaluators.Evaluators\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "import com.salesforce.op._\n",
    "import com.salesforce.op.features._\n",
    "import com.salesforce.op.features.types._\n",
    "import com.salesforce.op.stages.impl.classification._\n",
    "import com.salesforce.op.evaluators.Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession$implicits$@2c8fc96f"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val conf = new SparkConf().setMaster(\"local[*]\").setAppName(\"automl-app\").setExecutorEnv(Array( (\"memory\", \"10g\"))) // Spark configuration\n",
    "val sc = new SparkContext(conf)  // initialize spark context\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)  // initialize sql context\n",
    "implicit val spark = SparkSession.builder.config(conf).getOrCreate() // start spark session \n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(spark.driver.host,R90RY1SX.myfnb.us), (spark.executorEnv.memory,10g), (spark.app.name,automl-app), (spark.master,local[*]), (spark.executor.id,driver), (spark.driver.port,51769), (spark.app.id,local-1549338046942)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.getAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawData = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"data/train.csv\")\n",
    "rawData.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
      "[1,0,3,Braund, Mr. Owen Harris,male,22.0,1,0,A/5 21171,7.25,null,S]\n",
      "[2,1,1,Cumings, Mrs. John Bradley (Florence Briggs Thayer),female,38.0,1,0,PC 17599,71.2833,C85,C]\n",
      "[3,1,3,Heikkinen, Miss. Laina,female,26.0,0,0,STON/O2. 3101282,7.925,null,S]\n",
      "[4,1,1,Futrelle, Mrs. Jacques Heath (Lily May Peel),female,35.0,1,0,113803,53.1,C123,S]\n",
      "[5,0,3,Allen, Mr. William Henry,male,35.0,0,0,373450,8.05,null,S]\n"
     ]
    }
   ],
   "source": [
    "println(rawData.columns.mkString(\",\"))\n",
    "rawData.take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: int, survived: double ... 10 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cast all non doulbe numeric types to double\n",
    "rawData.createOrReplaceTempView(\"raw\")\n",
    "val passengerData = spark.sql(\"\"\"\n",
    "    select \n",
    "      passengerId as id, \n",
    "      cast(survived as double) as survived, \n",
    "      cast(pclass as string) as pclass, name, sex, age, \n",
    "      sibsp, parch, ticket, \n",
    "      fare, cabin, embarked \n",
    "      from raw\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "| id|survived|pclass|                name|   sex| age|sibsp|parch|          ticket|   fare|cabin|embarked|\n",
      "+---+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|  1|     0.0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|  2|     1.0|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|  3|     1.0|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|  4|     1.0|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|  5|     0.0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|  6|     0.0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|  7|     0.0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|  8|     0.0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|  9|     1.0|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "| 10|     1.0|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "| 11|     1.0|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "| 12|     1.0|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "| 13|     0.0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "| 14|     0.0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "| 15|     0.0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "| 16|     1.0|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "| 17|     0.0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "| 18|     1.0|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "| 19|     0.0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "| 20|     1.0|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+---+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passengerData.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Target and Features\n",
    "\n",
    "Features for our dataset could come in all types of flavors.  We could have location data, email address, text, addresses, etc, but for our purposes we would broadly clsasify our features as either text of numeric.  This broad classification will affect the feature engineering step of our workflow because the feature engineering has predefined routines based on the type of the feature.  For instance, with a feature that is an email address, it may parse out the domain and generate a one hote encoder for the top $k$ domains.  For our purposes, text and numeric will work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: int, survived: double ... 10 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train, test) = passengerData.randomSplit(Array(0.7, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that the type parameterization on `FeatureBuilder.fromDataFrame` concerns the repsonse field.  Below we have `RealNN` which is a real number which is not nullable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (target, features) = FeatureBuilder.fromDataFrame[RealNN](train, response = \"survived\")\n",
    "OutputCell.HIDDEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = id, uid = Integral_000000000001, isResponse = false, originStage = FeatureGeneratorStage_000000000001, parents = [], distributions = [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val id = features(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transmogrify (Automated Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminate the id field as it doesn't make sense as a feature.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = age-cabin-embarked-fare-name-parch-pclass-sex-sibsp-ticket_4-stagesApplied_OPVector_000000000010, uid = OPVector_000000000010, isResponse = false, originStage = VectorsCombiner_000000000010, parents = [OPVector_00000000000d,OPVector_00000000000e,OPVector_00000000000f], distributions = [])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureVector = features.filter{ _.name != \"id\" }.transmogrify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-- combVec\n",
       "|    +-- smartTxtVec\n",
       "|    |    +-- ConcatText(embarked)\n",
       "|    |    +-- ConcatText(cabin)\n",
       "|    |    +-- ConcatText(ticket)\n",
       "|    |    +-- ConcatText(sex)\n",
       "|    |    +-- ConcatText(name)\n",
       "|    |    +-- ConcatText(pclass)\n",
       "|    +-- vecReal\n",
       "|    |    +-- SumReal(fare)\n",
       "|    |    +-- SumReal(age)\n",
       "|    +-- vecInt\n",
       "|    |    +-- SumIntegral(parch)\n",
       "|    |    +-- SumIntegral(sibsp)\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureVector.prettyParentStages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fillValue: default value for FillWithConstant (default: 0)\n",
       "\n",
       "inputFeatures: Input features (default: [Lcom.salesforce.op.features.TransientFeature;@6cf9dd0b, current: [Lcom.salesforce.op.features.TransientFeature;@549e2c1a)\n",
       "\n",
       "inputSchema: the schema of the input data from the dataframe (default: StructType())\n",
       "\n",
       "outputFeatureName: output name that overrides default output name for feature made by this stage (undefined)\n",
       "\n",
       "outputMetadata: any metadata that user wants to save in the transformed DataFrame (default: {}, current: {\"ml_attr\":{\"attrs\":{\"numeric\":[{\"idx\":0,\"name\":\"sibsp_0\"},{\"idx\":1,\"name\":\"parch_1\"}]},\"num_attrs\":2},\"vector_history\":{\"sibsp\":{\"stages\":[\"vecInt_IntegralVectorizer_00000000000d\"],\"origin_features\":[\"sibsp\"]},\"parch\":{\"stages\":[\"vecInt_IntegralVectorizer_00000000000d\"],\"origin_features\":[\"parch\"]}},\"vector_columns\":[{\"indices\":[1],\"parent_feature_type\":[\"com.salesforce.op.features.types.Integral\"],\"parent_feature\":[\"parch\"]},{\"indices\":[0],\"parent_feature_type\":[\"com.salesforce.op.features.types.Integral\"],\"parent_feature\":[\"sibsp\"]}]})\n",
       "\n",
       "trackNulls: option to keep track of values that were missing (default: true, current: true)\n",
       "\n",
       "fillWithConstant: boolean to check if filling the nulls with a constant value (default: true, current: false)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureVector.parents(0).originStage.explainParams.split(\"\\n\").mkString(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = pclass, uid = Text_000000000003, isResponse = false, originStage = FeatureGeneratorStage_000000000003, parents = [], distributions = [])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "input is incomplete",
     "evalue": "input is incomplete",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31minput is incomplete\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "//featureVector.parents(1).originStage.explainParams.split(\"\\n\").mkString(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check (Feature Refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val checkFeatures = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = age-cabin-embarked-fare-name-parch-pclass-sex-sibsp-ticket_4-stagesApplied_OPVector_000000000010, uid = OPVector_000000000010, isResponse = false, originStage = VectorsCombiner_000000000010, parents = [OPVector_00000000000d,OPVector_00000000000e,OPVector_00000000000f], distributions = [])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val checkedFeatures = if(checkFeatures) target.sanityCheck(featureVector, removeBadFeatures = true) else featureVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputFeatures: Input features (default: [Lcom.salesforce.op.features.TransientFeature;@183fd255, current: [Lcom.salesforce.op.features.TransientFeature;@38136ff6)\n",
      "\n",
      "inputSchema: the schema of the input data from the dataframe (default: StructType())\n",
      "\n",
      "outputFeatureName: output name that overrides default output name for feature made by this stage (undefined)\n",
      "\n",
      "outputMetadata: any metadata that user wants to save in the transformed DataFrame (default: {})\n"
     ]
    }
   ],
   "source": [
    "println(checkedFeatures.originStage.explainParams.split(\"\\n\").mkString(\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelSelector_000000000041"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// error\n",
    "// auROC\n",
    "// auPR\n",
    "val modelSelector = BinaryClassificationModelSelector.withCrossValidation(numFolds = 3, parallelism=10 //, validationMetric = Evaluators.BinaryClassification.auPR\n",
    "                                                                         )\n",
    ".setInput(target, checkedFeatures).setOutputFeatureName(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c47251d-147d-485f-9b4f-64c3d9b72e14",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelSelector.validator.getParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total models to estimate: 48\n"
     ]
    }
   ],
   "source": [
    "println(s\"total models to estimate: ${modelSelector.models.map(i => i._2.length).sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(name = prediction, uid = Prediction_00000000001c, isResponse = true, originStage = ModelSelector_00000000001c, parents = [RealNN_000000000002,OPVector_000000000010], distributions = [])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prediction = modelSelector.getOutput()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a TransmogrifAI Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.salesforce.op.OpWorkflow@6541e029"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val workflow = new OpWorkflow().setInputDataset(train).setResultFeatures(id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpWorkflow_000000000042"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "input is incomplete",
     "evalue": "input is incomplete",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31minput is incomplete\u001b[0;0m"
     ]
    }
   ],
   "source": [
    "// val fittedWorkflow = workflow.loadModel(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.salesforce.op.OpWorkflowModel@1b9d95f"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fittedWorkflow = workflow.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedWorkflow.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated OpLogisticRegression, OpLinearSVC, OpRandomForestClassifier, OpGBTClassifier models using Cross Validation and area under precision-recall metric.\n",
      "Evaluated 8 OpLogisticRegression models with area under precision-recall metric between [0.7536868326562881, 0.8190254684318203].\n",
      "Evaluated 4 OpLinearSVC models with area under precision-recall metric between [0.7416743180639309, 0.7461669122149207].\n",
      "Evaluated 18 OpRandomForestClassifier models with area under precision-recall metric between [0.6871269308007691, 0.7960781816903247].\n",
      "Evaluated 18 OpGBTClassifier models with area under precision-recall metric between [0.8072934000924459, 0.8392060064114096].\n",
      "+---------------------------------------------------------+\n",
      "|            Selected Model - OpGBTClassifier             |\n",
      "+---------------------------------------------------------+\n",
      "| Model Param           | Value                           |\n",
      "+-----------------------+---------------------------------+\n",
      "| cacheNodeIds          | false                           |\n",
      "| checkpointInterval    | 10                              |\n",
      "| featureSubsetStrategy | all                             |\n",
      "| impurity              | gini                            |\n",
      "| lossType              | logistic                        |\n",
      "| maxBins               | 32                              |\n",
      "| maxDepth              | 12                              |\n",
      "| maxIter               | 20                              |\n",
      "| maxMemoryInMB         | 256                             |\n",
      "| minInfoGain           | 0.001                           |\n",
      "| minInstancesPerNode   | 10                              |\n",
      "| modelType             | OpGBTClassifier                 |\n",
      "| name                  | OpGBTClassifier_000000000017_12 |\n",
      "| seed                  | 1918769265                      |\n",
      "| stepSize              | 0.1                             |\n",
      "| subsamplingRate       | 1.0                             |\n",
      "| uid                   | OpGBTClassifier_000000000017    |\n",
      "+-----------------------+---------------------------------+\n",
      "+-------------------------------------------------------------------------+\n",
      "|                        Model Evaluation Metrics                         |\n",
      "+-------------------------------------------------------------------------+\n",
      "| Metric Name                 | Training Set Value  | Hold Out Set Value  |\n",
      "+-----------------------------+---------------------+---------------------+\n",
      "| area under ROC              | 0.9812159229998888  | 0.7082051282051279  |\n",
      "| area under precision-recall | 0.9727807997147606  | 0.6426858564507013  |\n",
      "| brier score                 | 0.05771510429377274 | 0.21257257783621356 |\n",
      "| error                       | 0.07414104882459313 | 0.296875            |\n",
      "| f1                          | 0.9002433090024331  | 0.5957446808510639  |\n",
      "| false negative              | 24.0                | 11.0                |\n",
      "| false positive              | 17.0                | 8.0                 |\n",
      "| precision                   | 0.9158415841584159  | 0.6363636363636364  |\n",
      "| recall                      | 0.8851674641148325  | 0.56                |\n",
      "| true negative               | 327.0               | 31.0                |\n",
      "| true positive               | 185.0               | 14.0                |\n",
      "+-----------------------------+---------------------+---------------------+\n",
      "+------------------------------------------------------+\n",
      "|                  Top Model Insights                  |\n",
      "+------------------------------------------------------+\n",
      "| Top Positive Correlations  |       Correlation Value |\n",
      "+----------------------------+-------------------------+\n",
      "| embarked(embarked = null)  | -1.7976931348623157E308 |\n",
      "| embarked(embarked = other) | -1.7976931348623157E308 |\n",
      "| embarked(embarked = Q)     | -1.7976931348623157E308 |\n",
      "| embarked(embarked = C)     | -1.7976931348623157E308 |\n",
      "| embarked(embarked = S)     | -1.7976931348623157E308 |\n",
      "| sibsp(sibsp = null)        | -1.7976931348623157E308 |\n",
      "| sibsp                      | -1.7976931348623157E308 |\n",
      "| pclass(pclass = null)      | -1.7976931348623157E308 |\n",
      "| pclass(pclass = other)     | -1.7976931348623157E308 |\n",
      "| pclass(pclass = 2)         | -1.7976931348623157E308 |\n",
      "| pclass(pclass = 1)         | -1.7976931348623157E308 |\n",
      "| pclass(pclass = 3)         | -1.7976931348623157E308 |\n",
      "| sex(sex = null)            | -1.7976931348623157E308 |\n",
      "| sex(sex = other)           | -1.7976931348623157E308 |\n",
      "| sex(sex = Female)          | -1.7976931348623157E308 |\n",
      "+----------------------------+-------------------------+\n",
      "+----------------------------------------------------+\n",
      "| Top Negative Correlations |      Correlation Value |\n",
      "+---------------------------+------------------------+\n",
      "| name                      | 1.7976931348623157E308 |\n",
      "| name(name = null)         | 1.7976931348623157E308 |\n",
      "| fare                      | 1.7976931348623157E308 |\n",
      "| fare(fare = null)         | 1.7976931348623157E308 |\n",
      "| parch                     | 1.7976931348623157E308 |\n",
      "| parch(parch = null)       | 1.7976931348623157E308 |\n",
      "| age                       | 1.7976931348623157E308 |\n",
      "| age(age = null)           | 1.7976931348623157E308 |\n",
      "| ticket                    | 1.7976931348623157E308 |\n",
      "| ticket(ticket = null)     | 1.7976931348623157E308 |\n",
      "| cabin                     | 1.7976931348623157E308 |\n",
      "| cabin(cabin = null)       | 1.7976931348623157E308 |\n",
      "| sex(sex = Male)           | 1.7976931348623157E308 |\n",
      "| sex(sex = Female)         | 1.7976931348623157E308 |\n",
      "| sex(sex = other)          | 1.7976931348623157E308 |\n",
      "+---------------------------+------------------------+\n",
      "+------------------------------------------------+\n",
      "| Top Contributions      |    Contribution Value |\n",
      "+------------------------+-----------------------+\n",
      "| fare                   |   0.29149080260662447 |\n",
      "| age                    |   0.24873276102206127 |\n",
      "| name                   |    0.0961894848439939 |\n",
      "| sibsp                  |  0.058426312588046134 |\n",
      "| sex(sex = Male)        |   0.04150343918954013 |\n",
      "| parch                  |  0.035405228299497715 |\n",
      "| pclass(pclass = 3)     |   0.03134287794037328 |\n",
      "| embarked(embarked = S) |  0.028316439715214737 |\n",
      "| embarked(embarked = C) |   0.02017410873768301 |\n",
      "| ticket                 |   0.01779714389310699 |\n",
      "| age(age = null)        |  0.011994710663432903 |\n",
      "| cabin(cabin = null)    |  0.010871399486371931 |\n",
      "| embarked(embarked = Q) |  0.006763549191371107 |\n",
      "| pclass(pclass = 1)     |  0.004194515480930404 |\n",
      "| pclass(pclass = 2)     | 0.0026058403346318126 |\n",
      "+------------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "println(fittedWorkflow.summaryPretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpBinaryClassificationEvaluator_000000000067"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = Evaluators.BinaryClassification()\n",
    "   .setLabelCol(target)\n",
    "   .setPredictionCol(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelCol: label column name (default: label, current: survived)\n",
       "predictionCol: prediction column name (current: prediction)\n",
       "predictionValueCol: prediction column name (default: prediction)\n",
       "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities (default: probability)\n",
       "rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.explainParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com.salesforce.op.OpWorkflowModel@1b9d95f"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedWorkflow.setInputDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (scoredTestData, metrics) = fittedWorkflow.scoreAndEvaluate(evaluator = evaluator)\n",
    "OutputCell.HIDDEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c155ce-b7f7-47e2-993a-b887be17c626",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.toMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in Kaggle test data and score it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// import data\n",
    "\n",
    "val rawTestData = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"data/test.csv\")\n",
    "rawTestData.createOrReplaceTempView(\"rawTest\")\n",
    "val passengerTestData = spark.sql(\"\"\"\n",
    "    select \n",
    "      passengerId as id, \n",
    "      cast(1 as double) as survived, \n",
    "      cast(pclass as string) as pclass, name, sex, age, \n",
    "      sibsp, parch, ticket, \n",
    "      fare, cabin, embarked \n",
    "      from rawTest\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "fittedWorkflow.setInputDataset(passengerTestData)\n",
    "\n",
    "val output = fittedWorkflow.computeDataUpTo(prediction).select(\"id\", \"prediction\")\n",
    "\n",
    "import java.io.{File, PrintWriter}\n",
    "\n",
    "\n",
    "val getScore = udf{ map: Map[String, Double ] => map.get(\"probability_1\")}\n",
    "val local = output.withColumn(\"p\", getScore(output.col(\"prediction\"))).selectExpr(\"id\", \"case when p >= 0.5 then 1 else 0 end\").collect\n",
    "\n",
    "val myFile = new File(\"myprediction1.csv\")\n",
    "val pw = new PrintWriter(myFile)\n",
    "pw.write(\"PassengerId,Survived\\n\")\n",
    "local.foreach( record => pw.write(record.mkString(\",\") +\"\\n\"))\n",
    "\n",
    "pw.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy around 77-78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "",
   "name": "Scala",
   "nbconverter_exporter": "",
   "version": "2.11.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
